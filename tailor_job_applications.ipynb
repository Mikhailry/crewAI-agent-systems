{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e2f7cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4569215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from the crewAI libray.\n",
    "from crewai import Agent, Task, Crew\n",
    "from crewai_tools import ScrapeWebsiteTool, SerperDevTool\n",
    "\n",
    "# Initialize the tools\n",
    "search_tool = SerperDevTool()\n",
    "scrape_tool = ScrapeWebsiteTool()\n",
    "\n",
    "# import library\n",
    "from dotenv import load_dotenv\n",
    "import os #needed to call function\n",
    "import openai\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b6e0a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup configuration function\n",
    "def configure():\n",
    "    load_dotenv()\n",
    "    \n",
    "# load configuration\n",
    "configure()\n",
    "\n",
    "# get the key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "serper_api_key = os.getenv(\"SERPER_API_KEY\")\n",
    "\n",
    "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-4-turbo'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b19680f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to convert pdf to text\n",
    "def convert_pdf_to_text(pdf_path, text_path):\n",
    "    \"\"\"Convert PDF to text and save as text file\"\"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    with open(text_path, 'w', encoding='utf-8') as output_file:\n",
    "        output_file.write(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9981ee51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MIKHAIL RYBALCHENKO Bellevue, WA |312-731-7541 | Mikhail.Rybalchenko@gmail.com | U.S. Citizen   Business Intelligence Developer with 7+ years of experience building executive dashboards, data pipelines and automations using PowerBI, Tableau, Python scripting, Power Automate, ingesting data from a variety of sources including SQL databases, APIs, Snowflake, Salesforce. Skilled in cross-functional collaboration with Product and Operations teams to deliver impactful, data-driven decisions.   Skills / Certifications / Education BI / Viz: Power BI, Tableau, Looker Programming Languages: Python, R, SQL AI and ML: Tavily, Ollama, LlamaIndex, HuggingFace, ChromaDB, Facebook Prophet, ML modeling, CursorAI Cloud Platforms: AWS, Google Cloud, Azure Automation and Orchestration: Power Automate, Airflow Certifications: Datacamp Data Scientist with Python, edX Certificate for Large Language Models, Tableau Desktop Certified Associate, AWS Certified Data Analytics, AWS Solution Architect Associate Education: Master of Data Science, Illinois Institute of Technology, Chicago, IL Awards: SAP Emarsys Core Values Outstanding Professional Award    Paylocity, remote – Business Intelligence & Automation 01/2021 – present Own company-wide executive dashboards guiding Product & Ops.   • Designed 50+ dashboards in Power BI and 10+ automations for multiple teams, enabling real-time decision making and saving 750 hours of manual effort every month • Established data-visualization standards, including reusable template and data flows for data consistency across dashboards and reports • Built ML models using NLP for case classification, reducing manual sampling efforts and improving measurement of in-product guidance efficacy, saving 1100+ hours of manual work • Designed a dashboard that serves as a single source of truth for upcoming product releases, deployments and company-wide initiatives, saving ~400 hours of manual work per month, allowing teams to spend less time chasing release details, and helping to avoid errors. Report is used by C-suite, Product, Operation and Service orgs. Tools used: API, Python, Power BI, Power Automate.  • Collaborated cross-functionally with Product and Operations teams, to identify and collect data, perform feature engineering for a scoring system, enabling easy decision-making and increased accuracy for product managers in product development request prioritization, saving 110+ hours of manual work every month • Utilized Pendo API, Power Automate, and Power BI to enable comprehensive access to previously unavailable data, improving user experience analysis and in-product guidance performance evaluation • Built a model to forecast Knowledge portal usage with Python and Facebook Prophet library • Developed an approach and SQL-query to estimate concurrent usage of Knowledge portal licenses. Created a Power BI dashboard and set up an automation with Power Automate to notify admin when usage reaching certain thresholds to prevent service disruption • Designed an approach to measure and track effectiveness of the Knowledge portal. Quantitatively showed the value of the portal for the end-users securing funding to extend the program • Designed and analyzed A/B-testing results for in-product guidance     WIM.agency, remote – Data analyst 06/2018 – 01/2021 • Gathered business requirements and developed reporting dashboards using Google BigQuery and Looker to measure POS and Employees performance for a large US startup • Built ETL pipelines with Python, Google Cloud Functions and Cloud Scheduler to write processed data into MySQL DB, designed and developed reporting dashboard, helped to draw insights from data for a marketing department of large pharmaceutical company.   \\nCCC Information Services, Chicago, IL – Data Science intern 01/2019 – 05/2019 Built a model in Python to identify anomalies in AWS logs data using Robust Random Cut Forest algorithm  Udacity - Independent consultant, Business Analytics nanodegree 02/2019 – 08/2019 • Ran advanced analytics classes (SQL, Excel and Tableau)  EMARSYS (SAP company) 03/2013 – 08/2017 Strategist and Client Success Manager • Developed and implemented Customer Lifecycle Marketing strategy, increasing monthly revenue by 54% • Led a campaign to win back the major client, recouping EUR 500K in annual revenue • Led A/B-testing of AI-enabled features, resulting in a 3% increase in conversion rate \\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = './data/Mikhail-Rybalchenko-Resume-2025.pdf'\n",
    "text_path = './data/Mikhail-Rybalchenko-Resume-2025.txt'\n",
    "\n",
    "convert_pdf_to_text(pdf_path, text_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64a90f6",
   "metadata": {},
   "source": [
    "## crewAI Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ea20182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting batches in chromadb: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "from crewai_tools import (\n",
    "  FileReadTool,\n",
    "  ScrapeWebsiteTool,\n",
    "  MDXSearchTool,\n",
    "  SerperDevTool\n",
    ")\n",
    "\n",
    "search_tool = SerperDevTool() #search tool   \n",
    "scrape_tool = ScrapeWebsiteTool() #scrape tool  \n",
    "read_resume = FileReadTool(file_path=text_path) #read resume\n",
    "semantic_search_resume = MDXSearchTool(mdx=text_path) #semantic search resume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbd5884",
   "metadata": {},
   "source": [
    "## Creating Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d69f6475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 1: Researcher\n",
    "researcher = Agent(\n",
    "    role=\"Tech Job Researcher\",\n",
    "    goal=\"Make sure to do amazing analysis on \"\n",
    "         \"job posting to help job applicants\",\n",
    "    tools = [scrape_tool, search_tool],\n",
    "    verbose=True,\n",
    "    backstory=(\n",
    "        \"As a Job Researcher, your prowess in \"\n",
    "        \"navigating and extracting critical \"\n",
    "        \"information from job postings is unmatched.\"\n",
    "        \"Your skills help pinpoint the necessary \"\n",
    "        \"qualifications and skills sought \"\n",
    "        \"by employers, forming the foundation for \"\n",
    "        \"effective application tailoring.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd9e1190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 2: Profiler\n",
    "profiler = Agent(\n",
    "    role=\"Personal Profiler for Engineers\",\n",
    "    goal=\"Do increditble research on job applicants \"\n",
    "         \"to help them stand out in the job market\",\n",
    "    tools = [scrape_tool, search_tool,\n",
    "             read_resume, semantic_search_resume],\n",
    "    verbose=True,\n",
    "    backstory=(\n",
    "        \"Equipped with analytical prowess, you dissect \"\n",
    "        \"and synthesize information \"\n",
    "        \"from diverse sources to craft comprehensive \"\n",
    "        \"personal and professional profiles, laying the \"\n",
    "        \"groundwork for personalized resume enhancements.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9af18258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 3: Resume Strategist\n",
    "resume_strategist = Agent(\n",
    "    role=\"Resume Strategist for Engineers\",\n",
    "    goal=\"Find all the best ways to make a \"\n",
    "         \"resume stand out in the job market.\",\n",
    "    tools = [scrape_tool, search_tool,\n",
    "             read_resume, semantic_search_resume],\n",
    "    verbose=True,\n",
    "    backstory=(\n",
    "        \"With a strategic mind and an eye for detail, you \"\n",
    "        \"excel at refining resumes to highlight the most \"\n",
    "        \"relevant skills and experiences, ensuring they \"\n",
    "        \"resonate perfectly with the job's requirements.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8b041a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 4: Interview Preparer\n",
    "interview_preparer = Agent(\n",
    "    role=\"Engineering Interview Preparer\",\n",
    "    goal=\"Create interview questions and talking points \"\n",
    "         \"based on the resume and job requirements\",\n",
    "    tools = [scrape_tool, search_tool,\n",
    "             read_resume, semantic_search_resume],\n",
    "    verbose=True,\n",
    "    backstory=(\n",
    "        \"Your role is crucial in anticipating the dynamics of \"\n",
    "        \"interviews. With your ability to formulate key questions \"\n",
    "        \"and talking points, you prepare candidates for success, \"\n",
    "        \"ensuring they can confidently address all aspects of the \"\n",
    "        \"job they are applying for.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f040ba6",
   "metadata": {},
   "source": [
    "## Creating Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "808ffdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task for Researcher Agent: Extract Job Requirements\n",
    "research_task = Task(\n",
    "    description=(\n",
    "        \"Analyze the job posting URL provided ({job_posting_url}) \"\n",
    "        \"to extract key skills, experiences, and qualifications \"\n",
    "        \"required. Use the tools to gather content and identify \"\n",
    "        \"and categorize the requirements.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A structured list of job requirements, including necessary \"\n",
    "        \"skills, qualifications, and experiences.\"\n",
    "    ),\n",
    "    agent=researcher,\n",
    "    async_execution=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7cc1738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task for Profiler Agent: Compile Comprehensive Profile\n",
    "profile_task = Task(\n",
    "    description=(\n",
    "        \"Compile a detailed personal and professional profile \"\n",
    "        \"using the GitHub ({github_url}) URLs, and personal write-up \"\n",
    "        \"({personal_writeup}). Utilize tools to extract and \"\n",
    "        \"synthesize information from these sources.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A comprehensive profile document that includes skills, \"\n",
    "        \"project experiences, contributions, interests, and \"\n",
    "        \"communication style.\"\n",
    "    ),\n",
    "    agent=profiler,\n",
    "    async_execution=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c585524",
   "metadata": {},
   "source": [
    "- You can pass a list of tasks as `context` to a task.\n",
    "- The task then takes into account the output of those tasks in its execution.\n",
    "- The task will not run until it has the output(s) from those tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6d3a773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task for Resume Strategist Agent: Align Resume with Job Requirements\n",
    "resume_strategy_task = Task(\n",
    "    description=(\n",
    "        \"Using the profile and job requirements obtained from \"\n",
    "        \"previous tasks, tailor the resume to highlight the most \"\n",
    "        \"relevant areas. Employ tools to adjust and enhance the \"\n",
    "        \"resume content. Make sure this is the best resume even but \"\n",
    "        \"don't make up any information. Update every section, \"\n",
    "        \"inlcuding the initial summary, work experience, skills, \"\n",
    "        \"and education. All to better reflrect the candidates \"\n",
    "        \"abilities and how it matches the job posting.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"An updated resume that effectively highlights the candidate's \"\n",
    "        \"qualifications and experiences relevant to the job.\"\n",
    "    ),\n",
    "    output_file=\"tailored_resume.md\",\n",
    "    context=[research_task, profile_task],\n",
    "    agent=resume_strategist\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15d30353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task for Interview Preparer Agent: Develop Interview Materials\n",
    "interview_preparation_task = Task(\n",
    "    description=(\n",
    "        \"Create a set of potential interview questions and talking \"\n",
    "        \"points based on the tailored resume and job requirements. \"\n",
    "        \"Utilize tools to generate relevant questions and discussion \"\n",
    "        \"points. Make sure to use these question and talking points to \"\n",
    "        \"help the candiadte highlight the main points of the resume \"\n",
    "        \"and how it matches the job posting.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A document containing key questions and talking points \"\n",
    "        \"that the candidate should prepare for the initial interview.\"\n",
    "    ),\n",
    "    output_file=\"interview_materials.md\",\n",
    "    context=[research_task, profile_task, resume_strategy_task],\n",
    "    agent=interview_preparer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f306889c",
   "metadata": {},
   "source": [
    "## Creating the Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff715992",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_application_crew = Crew(\n",
    "    agents=[researcher,\n",
    "            profiler,\n",
    "            resume_strategist,\n",
    "            interview_preparer],\n",
    "\n",
    "    tasks=[research_task,\n",
    "           profile_task,\n",
    "           resume_strategy_task,\n",
    "           interview_preparation_task],\n",
    "\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f3b368",
   "metadata": {},
   "source": [
    "## Running the Crew\n",
    "\n",
    "- Set the inputs for the execution of the crew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acacd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_application_inputs = {\n",
    "    'job_posting_url': 'https://jobs.lever.co/AIFund/6c82e23e-d954-4dd8-a734-c0c2c5ee00f1?lever-origin=applied&lever-source%5B%5D=AI+Fund',\n",
    "    'github_url': 'https://github.com/joaomdmoura',\n",
    "    'personal_writeup': \"\"\"Noah is an accomplished Software\n",
    "    Engineering Leader with 18 years of experience, specializing in\n",
    "    managing remote and in-office teams, and expert in multiple\n",
    "    programming languages and frameworks. He holds an MBA and a strong\n",
    "    background in AI and data science. Noah has successfully led\n",
    "    major tech initiatives and startups, proving his ability to drive\n",
    "    innovation and growth in the tech industry. Ideal for leadership\n",
    "    roles that require a strategic and innovative approach.\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77317074",
   "metadata": {},
   "outputs": [],
   "source": [
    "### this execution will take a few minutes to run\n",
    "result = job_application_crew.kickoff(inputs=job_application_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c32d161",
   "metadata": {},
   "source": [
    "- Dislplay the generated `tailored_resume.md` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f24add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display(Markdown(\"./tailored_resume.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bc240f",
   "metadata": {},
   "source": [
    "- Dislplay the generated `interview_materials.md` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30349f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crewai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
